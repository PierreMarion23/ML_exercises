{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AMAL - TP 4 - Réseaux récurrents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:This caffe2 python run does not have GPU support. Will run in CPU only mode.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from datamaestro import prepare_dataset \n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "import csv\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implémentation du RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_old(torch.nn.Module):\n",
    "    def __init__(self, dim, latent):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.Wi = torch.nn.Linear(dim, latent, bias=False)\n",
    "        self.Wh = torch.nn.Linear(latent, latent)\n",
    "        self.latent = latent\n",
    "    \n",
    "    def one_step(self, x, h):\n",
    "        return torch.nn.Tanh()(self.Wi(x) + self.Wh(h)) \n",
    "       # return torch.nn.Tanh()(self.Wi(x) + self.Wh(h)) + h ####\n",
    "    \n",
    "    def forward(self, x, h):\n",
    "        length, batch = x.shape[0], x.shape[1] \n",
    "        hs = torch.zeros(length, batch, self.latent)\n",
    "        for i in range(length):\n",
    "            h = self.one_step(x[i], h)\n",
    "            hs[i] = h\n",
    "        return hs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(torch.nn.Module):\n",
    "    def __init__(self, dim, latent):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.Wi = torch.nn.Linear(dim, latent, bias=False)\n",
    "        self.Wh = torch.nn.Linear(latent, latent)\n",
    "        self.latent = latent\n",
    "    \n",
    "    def one_step(self, x, h):\n",
    "        return torch.nn.Tanh()(self.Wi(x) + self.Wh(h)) \n",
    "       # return torch.nn.Tanh()(self.Wi(x) + self.Wh(h)) + h ####\n",
    "    \n",
    "    def forward(self, x, h):\n",
    "        length, batch = x.shape[0], x.shape[1] \n",
    "        hs = torch.zeros(length, batch, self.latent)\n",
    "        hs[0] = self.one_step(x[0], h)\n",
    "        for i in range(1, length):\n",
    "            hs[i] = self.one_step(x[i], hs[i-1])\n",
    "        return hs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 10, 3])\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    batch = 10\n",
    "    dim = 5\n",
    "    latent = 3\n",
    "    length = 6\n",
    "    x = torch.randn(length, batch, dim, requires_grad=True,dtype=torch.float)\n",
    "    h = torch.randn(batch, latent, requires_grad=True,dtype=torch.float)\n",
    "    rnn = RNN(dim, latent)\n",
    "    print(rnn.forward(x, h).shape)\n",
    "    \n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exo 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cities = 2\n",
    "dim = 1\n",
    "batch = 1\n",
    "latent = 2\n",
    "length = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>Vancouver</th>\n",
       "      <th>Portland</th>\n",
       "      <th>San Francisco</th>\n",
       "      <th>Seattle</th>\n",
       "      <th>Los Angeles</th>\n",
       "      <th>San Diego</th>\n",
       "      <th>Las Vegas</th>\n",
       "      <th>Phoenix</th>\n",
       "      <th>Albuquerque</th>\n",
       "      <th>...</th>\n",
       "      <th>Detroit</th>\n",
       "      <th>Jacksonville</th>\n",
       "      <th>Charlotte</th>\n",
       "      <th>Miami</th>\n",
       "      <th>Pittsburgh</th>\n",
       "      <th>Toronto</th>\n",
       "      <th>Philadelphia</th>\n",
       "      <th>New York</th>\n",
       "      <th>Montreal</th>\n",
       "      <th>Boston</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2012-10-01 13:00:00</td>\n",
       "      <td>284.630000</td>\n",
       "      <td>282.080000</td>\n",
       "      <td>289.480000</td>\n",
       "      <td>281.800000</td>\n",
       "      <td>291.870000</td>\n",
       "      <td>291.530000</td>\n",
       "      <td>293.410000</td>\n",
       "      <td>296.600000</td>\n",
       "      <td>285.120000</td>\n",
       "      <td>...</td>\n",
       "      <td>284.030000</td>\n",
       "      <td>298.170000</td>\n",
       "      <td>288.650000</td>\n",
       "      <td>299.720000</td>\n",
       "      <td>281.000000</td>\n",
       "      <td>286.260000</td>\n",
       "      <td>285.630000</td>\n",
       "      <td>288.220000</td>\n",
       "      <td>285.830000</td>\n",
       "      <td>287.170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2012-10-01 14:00:00</td>\n",
       "      <td>284.629041</td>\n",
       "      <td>282.083252</td>\n",
       "      <td>289.474993</td>\n",
       "      <td>281.797217</td>\n",
       "      <td>291.868186</td>\n",
       "      <td>291.533501</td>\n",
       "      <td>293.403141</td>\n",
       "      <td>296.608509</td>\n",
       "      <td>285.154558</td>\n",
       "      <td>...</td>\n",
       "      <td>284.069789</td>\n",
       "      <td>298.205230</td>\n",
       "      <td>288.650172</td>\n",
       "      <td>299.732518</td>\n",
       "      <td>281.024767</td>\n",
       "      <td>286.262541</td>\n",
       "      <td>285.663208</td>\n",
       "      <td>288.247676</td>\n",
       "      <td>285.834650</td>\n",
       "      <td>287.186092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2012-10-01 15:00:00</td>\n",
       "      <td>284.626998</td>\n",
       "      <td>282.091866</td>\n",
       "      <td>289.460618</td>\n",
       "      <td>281.789833</td>\n",
       "      <td>291.862844</td>\n",
       "      <td>291.543355</td>\n",
       "      <td>293.392177</td>\n",
       "      <td>296.631487</td>\n",
       "      <td>285.233952</td>\n",
       "      <td>...</td>\n",
       "      <td>284.173965</td>\n",
       "      <td>298.299595</td>\n",
       "      <td>288.650582</td>\n",
       "      <td>299.766579</td>\n",
       "      <td>281.088319</td>\n",
       "      <td>286.269518</td>\n",
       "      <td>285.756824</td>\n",
       "      <td>288.326940</td>\n",
       "      <td>285.847790</td>\n",
       "      <td>287.231672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2012-10-01 16:00:00</td>\n",
       "      <td>284.624955</td>\n",
       "      <td>282.100481</td>\n",
       "      <td>289.446243</td>\n",
       "      <td>281.782449</td>\n",
       "      <td>291.857503</td>\n",
       "      <td>291.553209</td>\n",
       "      <td>293.381213</td>\n",
       "      <td>296.654466</td>\n",
       "      <td>285.313345</td>\n",
       "      <td>...</td>\n",
       "      <td>284.278140</td>\n",
       "      <td>298.393961</td>\n",
       "      <td>288.650991</td>\n",
       "      <td>299.800641</td>\n",
       "      <td>281.151870</td>\n",
       "      <td>286.276496</td>\n",
       "      <td>285.850440</td>\n",
       "      <td>288.406203</td>\n",
       "      <td>285.860929</td>\n",
       "      <td>287.277251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2012-10-01 17:00:00</td>\n",
       "      <td>284.622911</td>\n",
       "      <td>282.109095</td>\n",
       "      <td>289.431869</td>\n",
       "      <td>281.775065</td>\n",
       "      <td>291.852162</td>\n",
       "      <td>291.563063</td>\n",
       "      <td>293.370249</td>\n",
       "      <td>296.677445</td>\n",
       "      <td>285.392738</td>\n",
       "      <td>...</td>\n",
       "      <td>284.382316</td>\n",
       "      <td>298.488326</td>\n",
       "      <td>288.651401</td>\n",
       "      <td>299.834703</td>\n",
       "      <td>281.215421</td>\n",
       "      <td>286.283473</td>\n",
       "      <td>285.944057</td>\n",
       "      <td>288.485467</td>\n",
       "      <td>285.874069</td>\n",
       "      <td>287.322831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime   Vancouver    Portland  San Francisco     Seattle  \\\n",
       "0  2012-10-01 13:00:00  284.630000  282.080000     289.480000  281.800000   \n",
       "1  2012-10-01 14:00:00  284.629041  282.083252     289.474993  281.797217   \n",
       "2  2012-10-01 15:00:00  284.626998  282.091866     289.460618  281.789833   \n",
       "3  2012-10-01 16:00:00  284.624955  282.100481     289.446243  281.782449   \n",
       "4  2012-10-01 17:00:00  284.622911  282.109095     289.431869  281.775065   \n",
       "\n",
       "   Los Angeles   San Diego   Las Vegas     Phoenix  Albuquerque  ...  \\\n",
       "0   291.870000  291.530000  293.410000  296.600000   285.120000  ...   \n",
       "1   291.868186  291.533501  293.403141  296.608509   285.154558  ...   \n",
       "2   291.862844  291.543355  293.392177  296.631487   285.233952  ...   \n",
       "3   291.857503  291.553209  293.381213  296.654466   285.313345  ...   \n",
       "4   291.852162  291.563063  293.370249  296.677445   285.392738  ...   \n",
       "\n",
       "      Detroit  Jacksonville   Charlotte       Miami  Pittsburgh     Toronto  \\\n",
       "0  284.030000    298.170000  288.650000  299.720000  281.000000  286.260000   \n",
       "1  284.069789    298.205230  288.650172  299.732518  281.024767  286.262541   \n",
       "2  284.173965    298.299595  288.650582  299.766579  281.088319  286.269518   \n",
       "3  284.278140    298.393961  288.650991  299.800641  281.151870  286.276496   \n",
       "4  284.382316    298.488326  288.651401  299.834703  281.215421  286.283473   \n",
       "\n",
       "   Philadelphia    New York    Montreal      Boston  \n",
       "0    285.630000  288.220000  285.830000  287.170000  \n",
       "1    285.663208  288.247676  285.834650  287.186092  \n",
       "2    285.756824  288.326940  285.847790  287.231672  \n",
       "3    285.850440  288.406203  285.860929  287.277251  \n",
       "4    285.944057  288.485467  285.874069  287.322831  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_data_init = pd.read_csv('tempAMAL_train.csv')\n",
    "temp_data_init.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data = pd.read_csv('tempAMAL_train.csv')\n",
    "temp_data = temp_data.iloc[:,1: 1+n_cities]\n",
    "data = np.asarray(temp_data)\n",
    "cols = temp_data.columns\n",
    "\n",
    "n_times = data.shape[0]\n",
    "data[np.isnan(data)] = np.mean(data[~np.isnan(data)])\n",
    "data = data / 280\n",
    "#data *= 10 * n_times/ (np.linalg.norm(data)*length)\n",
    "data -= np.mean(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelectLast(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SelectLast, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "def test_select_last():\n",
    "    select_last = SelectLast()\n",
    "    x = torch.randn(5, 3)\n",
    "    print(select_last(x).shape)\n",
    "\n",
    "test_select_last()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mySequential(torch.nn.Sequential):\n",
    "    def forward(self, *inputs):\n",
    "        for module in self._modules.values():\n",
    "            if type(inputs) == tuple:\n",
    "                inputs = module(*inputs)\n",
    "            else:\n",
    "                inputs = module(inputs)\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "increment = np.repeat(np.arange(0, length), batch).reshape((length, batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mySequential(\n",
    "    RNN(dim, latent),\n",
    "    SelectLast(),\n",
    "    torch.nn.Linear(latent, n_cities),\n",
    "    torch.nn.Tanh()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.2005],\n",
      "        [-0.0374]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[0.5842, 0.1970],\n",
      "        [0.6545, 0.7026]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model[0].Wi.weight)\n",
    "print(model[0].Wh.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.5062, -0.4948],\n",
       "        [ 0.3467,  0.6599]], requires_grad=True)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[2].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "h0 = torch.zeros(batch, latent, requires_grad=True)\n",
    "optim = torch.optim.SGD(params=model.parameters(),lr=10*EPS)\n",
    "#optim = torch.optim.Adam(params=[x for x in model.parameters()] + [h0], lr=0.1,etas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "loss = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00449842555105713"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch * length * 100 / (data.shape[0]*data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = 100\n",
    "writer = SummaryWriter()\n",
    "\n",
    "for i in range(n_train):\n",
    "    # each time: we see batch * length data\n",
    "    optim.zero_grad()\n",
    "    random_cities = np.random.randint(0, n_cities, size=(batch))\n",
    " #   random_times = np.random.randint(0, n_times-length, size=(batch))\n",
    "    random_times = np.zeros(batch, dtype=np.int)\n",
    "    x_numpy = data[np.repeat(np.reshape(random_times, (1, batch)), length, axis=0)+increment, random_cities][:, :, np.newaxis]\n",
    "    x = torch.from_numpy(x_numpy).float()\n",
    "    l = loss(model(x, h0), torch.from_numpy(random_cities))\n",
    "    l.backward()\n",
    "   # print(model[0].Wh.weight.grad)\n",
    "    optim.step()\n",
    "    writer.add_scalar('Loss/train', l, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6953, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-7.4252e-06],\n",
      "        [ 1.6971e-05]])\n",
      "Parameter containing:\n",
      "tensor([[ 0.1982],\n",
      "        [-0.0557]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(model[0].Wi.weight.grad)\n",
    "print(model[0].Wi.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39\n"
     ]
    }
   ],
   "source": [
    "n_test = 100\n",
    "# writer = SummaryWriter()\n",
    "p_true = 0\n",
    "\n",
    "for i in range(n_test):\n",
    "    with torch.no_grad():\n",
    "        random_cities = np.random.randint(0, n_cities, size=(batch))\n",
    "      #  random_times = np.random.randint(0, n_times-length, size=(batch))\n",
    "        random_times = np.zeros(batch, dtype=np.int)\n",
    "        x_numpy = data[np.repeat(np.reshape(random_times, (1, batch)), length, axis=0)+increment, random_cities][:, :, np.newaxis]\n",
    "        x = torch.from_numpy(x_numpy).float()\n",
    "        predicted_cities = model(x, h0).detach().numpy()\n",
    "        ok = np.sum(np.argmax(predicted_cities, axis=1) == random_cities) / batch\n",
    "        p_true += ok\n",
    "        \n",
    "print(p_true / n_test)\n",
    "        #random_cities\n",
    "       # print(model[0].Wh.weight.grad)\n",
    "       # writer.add_scalar('Loss/train', l, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
